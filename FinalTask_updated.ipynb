{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5a68e9-d1c5-45c0-9ca1-c740ca232bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2f573-0f17-4518-b830-3b4e10604492",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_result = [] # table/DQ check/ Column/ Status/ Bad Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedcc60a-1c7d-4b76-b315-9b55722c3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_files(parquet_files):\n",
    "    dataframes = [pd.read_parquet(file) for file in parquet_files]\n",
    "    my_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return my_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abbbf93-0622-47af-aa63-26ed1b34302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_value(column_raw):\n",
    "    if column_raw == \"NA\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(column_raw or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10fc62-5fb4-4a63-b4f3-2d23741bb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_column_value_is_empty(column_value):\n",
    "    return True if (column_value is None or column_value == \"\") else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011cb5b-0b28-4e7e-a7b6-9ce78e3089b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_format(row, column_name):\n",
    "    value = get_column_value(row[column_name])\n",
    "    if not len(str(get_column_value(row[column_name]))) == 4:\n",
    "        final_result.append(('Flights', 'Validity', column_name, \"Failed\", f\"Time format for {row['TailNum']}/{row['FlightNum']}:  {value}\"))\n",
    "    else:\n",
    "        if not 0 <= value <= 2359:\n",
    "            final_result.append(('Flights', 'Validity', column_name, \"Failed\", f\"Time format for {row['TailNum']}/{row['FlightNum']}:  {value}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a687c-aa13-4abe-82a8-188255d88e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Airports: Consistency check for state\n",
    "def check_consistency():\n",
    "    parquet_files = [\"part-00000-a9aee747-6f56-4317-bf6b-075fe3b3ed5f-c000.snappy.parquet\",\n",
    "                     \"part-00001-a9aee747-6f56-4317-bf6b-075fe3b3ed5f-c000.snappy.parquet\"]\n",
    "\n",
    "    my_df = read_parquet_files(parquet_files)\n",
    "\n",
    "    valid_states = [\n",
    "        \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\",\n",
    "        \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\",\n",
    "        \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\",\n",
    "        \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"]\n",
    "    inconsistency = []\n",
    "\n",
    "    for index, row in my_df.iterrows():\n",
    "        country = row[\"country\"]\n",
    "        state = row[\"state\"]\n",
    "        if country == \"USA\" and state in valid_states:\n",
    "            continue\n",
    "        else:\n",
    "            if state not in inconsistency and country != \"\":\n",
    "                final_result.append(['Airports', 'Consistency', 'State', 'Failed', state])\n",
    "                inconsistency.append(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2eb44-c36a-4a3a-bda6-2411673050eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Flights: Validity by time range\n",
    "def check_validity():\n",
    "    parquet_files = [\"part-00000-55c5be74-a9db-4265-8f2c-bceb8279269e-c000.snappy.parquet\",\n",
    "                         \"part-00001-55c5be74-a9db-4265-8f2c-bceb8279269e-c000.snappy.parquet\"]\n",
    "    \n",
    "    my_df = read_parquet_files(parquet_files)\n",
    "    \n",
    "    for index,row in my_df.iterrows():\n",
    "        check_time_format(row, \"ArrTime\")\n",
    "        check_time_format(row, \"CRSArrTime\")\n",
    "        check_time_format(row, \"DepTime\")\n",
    "        check_time_format(row, \"CRSDepTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc9672-b308-4873-ab6e-43021a3a98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Flights: Consisntency check for ActualElapsedTime\n",
    "def check_consistency_for_ActualElapsedTime():\n",
    "    parquet_files = [\"part-00000-55c5be74-a9db-4265-8f2c-bceb8279269e-c000.snappy.parquet\",\n",
    "                     \"part-00001-55c5be74-a9db-4265-8f2c-bceb8279269e-c000.snappy.parquet\"]\n",
    "\n",
    "    my_df = read_parquet_files(parquet_files)\n",
    "\n",
    "    for index, row in my_df.iterrows():\n",
    "        actual_elapsed_time = get_column_value(row[\"ActualElapsedTime\"])\n",
    "        arrival = get_column_value(row[\"ArrTime\"])\n",
    "        departure = get_column_value(row[\"DepTime\"])\n",
    "        expected_diff = arrival - departure\n",
    "        if actual_elapsed_time != expected_diff:\n",
    "            flightnum = row[\"FlightNum\"]\n",
    "            plane = row[\"TailNum\"]\n",
    "            final_result.append(('Flights', 'Consistency', \"ActualElapsedTime\", \"Failed\", f\"{plane}/{flightnum}: actual = {actual_elapsed_time}, expected = {expected_diff}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3b1ba-c7d9-4812-845e-2fcb347e90c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Carrier: Completeness by records\n",
    "def check_completeness():\n",
    "    parquet_files = [\"part-00000-366e67ad-4fd6-41cd-af99-1ff7b3e314db-c000.snappy.parquet\",\n",
    "                     \"part-00001-366e67ad-4fd6-41cd-af99-1ff7b3e314db-c000.snappy.parquet\"]\n",
    "\n",
    "    my_df = read_parquet_files(parquet_files)\n",
    "\n",
    "    for index,row in my_df.iterrows():\n",
    "        if check_column_value_is_empty(row[\"code\"]) or check_column_value_is_empty(row[\"description\"]):\n",
    "            final_result.append([\"Carriers\", \"Completeness\", [\"code\", \"description\"], \"Failed\", f\"code = {row['code']} description = {row['description']}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8518a-764b-4a85-aaee-702a9effd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_consistency()\n",
    "check_validity()\n",
    "check_consistency_for_ActualElapsedTime()\n",
    "check_completeness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22027cc3-3530-43ef-98ca-8854ce3f80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_result, columns=[\"Table\", \"DQ check\", \"Column\", \"Status\", \"Bad Data\"])\n",
    "\n",
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "df.index = np.arange(1, len(df) + 1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866fc3a-b6c1-4c75-93dd-e6a992fb3702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
